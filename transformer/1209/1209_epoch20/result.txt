2024-12-09 18:39:58.288423: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-12-09 18:39:58.298409: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2024-12-09 18:39:58.308702: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2024-12-09 18:39:58.311726: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-12-09 18:39:58.319781: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-12-09 18:39:58.915337: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT

Epoch 1/20: 100%|█████████████████████████████████| 1008/1008 [00:14<00:00, 71.26it/s, loss=2.92e+5]
Epoch [1/20], Total Loss:292495.8484
Epoch 2/20: 100%|█████████████████████████████████████| 1008/1008 [00:14<00:00, 71.10it/s, loss=554]
Epoch [2/20], Total Loss:554.1336
Checkpoint saved at epoch 1
Epoch 3/20: 100%|█████████████████████████████████████| 1008/1008 [00:14<00:00, 71.24it/s, loss=301]
Epoch [3/20], Total Loss:300.7507
Checkpoint saved at epoch 2
Epoch 4/20: 100%|█████████████████████████████████████| 1008/1008 [00:14<00:00, 71.25it/s, loss=222]
Epoch [4/20], Total Loss:221.7065
Checkpoint saved at epoch 3
Epoch 5/20: 100%|█████████████████████████████████████| 1008/1008 [00:14<00:00, 71.26it/s, loss=181]
Epoch [5/20], Total Loss:180.8295
Checkpoint saved at epoch 4
Epoch 6/20: 100%|█████████████████████████████████████| 1008/1008 [00:14<00:00, 71.14it/s, loss=150]
Epoch [6/20], Total Loss:149.5218
Checkpoint saved at epoch 5
Epoch 7/20: 100%|█████████████████████████████████████| 1008/1008 [00:14<00:00, 71.18it/s, loss=103]
Epoch [7/20], Total Loss:102.8144
Checkpoint saved at epoch 6
Epoch 8/20: 100%|█████████████████████████████████████| 1008/1008 [00:14<00:00, 71.23it/s, loss=116]
Epoch [8/20], Total Loss:116.2025
Epoch 9/20: 100%|████████████████████████████████████| 1008/1008 [00:14<00:00, 71.60it/s, loss=50.2]
Epoch [9/20], Total Loss:50.2474
Checkpoint saved at epoch 8
Epoch 10/20: 100%|████████████████████████████████| 1008/1008 [00:14<00:00, 71.32it/s, loss=6.28e+3]
Epoch [10/20], Total Loss:6279.8705
Loss exploded! Reloading from last checkpoint...
Checkpoint loaded. Resuming from epoch 8 with loss 0.0174
Epoch 11/20: 100%|███████████████████████████████████| 1008/1008 [00:14<00:00, 71.28it/s, loss=59.7]
Epoch 00011: reducing learning rate of group 0 to 2.0000e-04.
Epoch [11/20], Total Loss:59.7225
Epoch 12/20: 100%|███████████████████████████████████| 1008/1008 [00:14<00:00, 71.40it/s, loss=19.3]
Epoch [12/20], Total Loss:19.3049
Checkpoint saved at epoch 11
Epoch 13/20: 100%|███████████████████████████████████| 1008/1008 [00:14<00:00, 71.05it/s, loss=17.8]
Epoch [13/20], Total Loss:17.8014
Checkpoint saved at epoch 12
Epoch 14/20: 100%|███████████████████████████████████| 1008/1008 [00:14<00:00, 71.52it/s, loss=18.2]
Epoch [14/20], Total Loss:18.2306
Epoch 15/20: 100%|███████████████████████████████████| 1008/1008 [00:14<00:00, 71.38it/s, loss=19.5]
Epoch 00015: reducing learning rate of group 0 to 4.0000e-05.
Epoch [15/20], Total Loss:19.5427
Epoch 16/20: 100%|█████████████████████████████████████| 1008/1008 [00:14<00:00, 71.50it/s, loss=18]
Epoch [16/20], Total Loss:17.9838
Epoch 17/20: 100%|███████████████████████████████████| 1008/1008 [00:14<00:00, 71.29it/s, loss=17.9]
Epoch 00017: reducing learning rate of group 0 to 8.0000e-06.
Epoch [17/20], Total Loss:17.9339
Epoch 18/20: 100%|███████████████████████████████████| 1008/1008 [00:14<00:00, 71.43it/s, loss=17.5]
Epoch [18/20], Total Loss:17.5481
Checkpoint saved at epoch 17
Epoch 19/20: 100%|███████████████████████████████████| 1008/1008 [00:14<00:00, 71.66it/s, loss=17.6]
Epoch [19/20], Total Loss:17.5521
Epoch 20/20: 100%|███████████████████████████████████| 1008/1008 [00:14<00:00, 71.75it/s, loss=17.5]
Epoch [20/20], Total Loss:17.5299
Checkpoint saved at epoch 19

100%|████████████████████████████████████████████████████████████| 252/252 [00:01<00:00, 225.82it/s]

the Mean Square Error(MSE) of Reconstruction in Normal Signal : 
[0.04212324 0.04199935 0.0414537  0.04156077 0.04152917 0.04162238
 0.04178454 0.04192064 0.04181594 0.04144442 0.04171658 0.04188397
 0.04152079 0.04141751 0.04203716 0.04181667 0.04137804 0.04208973
 0.04190078 0.0422208  0.04163776 0.04181041 0.04194647 0.04181945
 0.04166013 0.04181736 0.04183046 0.04200283 0.0420504  0.04177441
 0.04214244 0.04177683 0.04170094 0.04172724 0.04188099 0.04166779
 0.0414907  0.04171458 0.0414286  0.04163481 0.04166071 0.04197086
 0.04171151 0.04169686 0.04177434 0.04151718 0.04187172 0.04185214
 0.04188061]

100%|████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 317.20it/s]

[[[-0.02949784  0.02778625  0.02227783  0.0401001 ]
  [-0.02949784  0.          0.06665039  0.06011963]
  [-0.02949784  0.04168701  0.06665039  0.06011963]
  ...
  [ 0.14579482  0.01390076  0.06665039  0.08001709]
  [ 0.14579482  0.01390076  0.06665039  0.06011963]
  [ 0.14579482  0.01390076  0.06665039  0.08001709]]]
[[[-0.02949784 -0.02670973  0.02227783  0.0401001 ]
  [-0.02949784 -0.09589665  0.06665039  0.06011963]
  [-0.02949784  0.00790274  0.06665039  0.06011963]
  ...
  [ 0.14579482 -0.0612842   0.06665039  0.08001709]
  [ 0.14579482 -0.0612842   0.06665039  0.06011963]
  [ 0.14579482 -0.0612842   0.06665039  0.08001709]]]
[[[-0.02949784 -0.02670973 -0.02516593  0.0401001 ]
  [-0.02949784 -0.09589665 -0.00688858  0.06011963]
  [-0.02949784  0.00790274 -0.00688858  0.06011963]
  ...
  [ 0.14579482 -0.0612842  -0.00688858  0.08001709]
  [ 0.14579482 -0.0612842  -0.00688858  0.06011963]
  [ 0.14579482 -0.0612842  -0.00688858  0.08001709]]]
[[[-0.02949784 -0.02670973 -0.02516593 -0.03145425]
  [-0.02949784 -0.09589665 -0.00688858 -0.02308007]
  [-0.02949784  0.00790274 -0.00688858 -0.02308007]
  ...
  [ 0.14579482 -0.0612842  -0.00688858 -0.01475694]
  [ 0.14579482 -0.0612842  -0.00688858 -0.02308007]
  [ 0.14579482 -0.0612842  -0.00688858 -0.01475694]]]

the Mean Square Error(MSE) of Reconstruction in Anomaly Signal : [0.10210902]

the Error of Reconstruction in Anomaly Channel C1 Signal : 123.72476196289062
the Error of Reconstruction in Anomaly Channel C2 Signal : -627.66455078125
the Error of Reconstruction in Anomaly Channel C3 Signal : -179.41192626953125
the Error of Reconstruction in Anomaly Channel C4 Signal : -285.7305908203125

100%|██████████████████████████████████████████████████████████| 1008/1008 [00:10<00:00, 100.17it/s]
100%|█████████████████████████████████████████████████████████████| 252/252 [00:02<00:00, 99.46it/s]
추론한 결과 : 손실밀도 히스토그램 시각화
추론 결과 : 손실값의 커널 밀도추정 시각화
추론 결과 : 손실값의 박스 그림 시각화