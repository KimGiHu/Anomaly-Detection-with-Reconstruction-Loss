2024-12-10 10:14:42.388567: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-12-10 10:14:42.398568: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2024-12-10 10:14:42.408912: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2024-12-10 10:14:42.411940: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-12-10 10:14:42.419965: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-12-10 10:14:43.012831: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
Epoch 1/20: 100%|█████████████████████████████████| 1008/1008 [00:14<00:00, 71.03it/s, loss=3.08e+5]
Epoch [1/20], Total Loss:308090.1700
Epoch 2/20: 100%|█████████████████████████████████| 1008/1008 [00:14<00:00, 71.30it/s, loss=7.23e+3]
Epoch [2/20], Total Loss:7225.9304
Checkpoint saved at epoch 1
Epoch 3/20: 100%|█████████████████████████████████| 1008/1008 [00:14<00:00, 71.42it/s, loss=4.57e+3]
Epoch [3/20], Total Loss:4568.3949
Checkpoint saved at epoch 2
Epoch 4/20: 100%|█████████████████████████████████| 1008/1008 [00:14<00:00, 71.25it/s, loss=4.96e+3]
Epoch [4/20], Total Loss:4962.7992
Epoch 5/20: 100%|█████████████████████████████████| 1008/1008 [00:14<00:00, 71.22it/s, loss=3.07e+3]
Epoch [5/20], Total Loss:3069.7954
Checkpoint saved at epoch 4
Epoch 6/20: 100%|██████████████████████████████████| 1008/1008 [00:14<00:00, 71.31it/s, loss=2.5e+3]
Epoch [6/20], Total Loss:2502.8220
Checkpoint saved at epoch 5
Epoch 7/20: 100%|█████████████████████████████████| 1008/1008 [00:14<00:00, 71.27it/s, loss=2.09e+3]
Epoch [7/20], Total Loss:2087.0086
Checkpoint saved at epoch 6
Epoch 8/20: 100%|█████████████████████████████████| 1008/1008 [00:14<00:00, 71.05it/s, loss=1.58e+3]
Epoch [8/20], Total Loss:1580.3624
Checkpoint saved at epoch 7
Epoch 9/20: 100%|█████████████████████████████████| 1008/1008 [00:14<00:00, 71.08it/s, loss=1.37e+3]
Epoch [9/20], Total Loss:1372.7514
Checkpoint saved at epoch 8
Epoch 10/20: 100%|████████████████████████████████| 1008/1008 [00:14<00:00, 71.31it/s, loss=1.12e+3]
Epoch [10/20], Total Loss:1115.4318
Checkpoint saved at epoch 9
Epoch 11/20: 100%|████████████████████████████████| 1008/1008 [00:14<00:00, 71.28it/s, loss=1.16e+3]
Epoch [11/20], Total Loss:1163.2264
Epoch 12/20: 100%|████████████████████████████████████| 1008/1008 [00:14<00:00, 71.37it/s, loss=808]
Epoch [12/20], Total Loss:808.4646
Checkpoint saved at epoch 11
Epoch 13/20: 100%|████████████████████████████████████| 1008/1008 [00:14<00:00, 71.18it/s, loss=698]
Epoch [13/20], Total Loss:697.9997
Checkpoint saved at epoch 12
Epoch 14/20: 100%|████████████████████████████████████| 1008/1008 [00:14<00:00, 71.10it/s, loss=665]
Epoch [14/20], Total Loss:664.8081
Checkpoint saved at epoch 13
Epoch 15/20: 100%|████████████████████████████████████| 1008/1008 [00:14<00:00, 71.02it/s, loss=544]
Epoch [15/20], Total Loss:543.8848
Checkpoint saved at epoch 14
Epoch 16/20: 100%|████████████████████████████████████| 1008/1008 [00:14<00:00, 71.06it/s, loss=948]
Epoch [16/20], Total Loss:948.1734
Epoch 17/20: 100%|████████████████████████████████████| 1008/1008 [00:14<00:00, 71.62it/s, loss=367]
Epoch [17/20], Total Loss:367.4446
Checkpoint saved at epoch 16
Epoch 18/20: 100%|████████████████████████████████████| 1008/1008 [00:14<00:00, 71.54it/s, loss=581]
Epoch [18/20], Total Loss:580.7306
Epoch 19/20: 100%|████████████████████████████████████| 1008/1008 [00:14<00:00, 71.38it/s, loss=517]
Epoch 00019: reducing learning rate of group 0 to 2.0000e-05.
Epoch [19/20], Total Loss:516.7400
Epoch 20/20: 100%|█████████████████████████████████████| 1008/1008 [00:14<00:00, 71.68it/s, loss=12]
Epoch [20/20], Total Loss:12.0337
Checkpoint saved at epoch 19
100%|████████████████████████████████████████████████████████████| 252/252 [00:01<00:00, 221.63it/s]
the Mean Square Error(MSE) of Reconstruction in Normal Signal : [0.0002698  0.00027056 0.00027999 0.00028304 0.00029294 0.00026963
 0.00027785 0.00028795 0.00027764 0.00029196 0.0002826  0.00028646
 0.00026259 0.00028125 0.00028084 0.00026726 0.00030524 0.00026789
 0.00029007 0.00027504 0.00027648 0.0002597  0.00027333 0.00027052
 0.00029593 0.0002834  0.00026171 0.00028512 0.00028696 0.00029287
 0.00025604 0.00027706 0.00026576 0.00030158 0.00027027 0.0002603
 0.00026501 0.00028149 0.00027138 0.00026445 0.00030849 0.00027697
 0.00030148 0.00028532 0.00026492 0.00027976 0.00026348 0.00025449
 0.0002843 ]
100%|████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 325.97it/s]
[[[-0.02949784  0.02778625  0.02227783  0.0401001 ]
  [-0.02949784  0.          0.06665039  0.06011963]
  [-0.02949784  0.04168701  0.06665039  0.06011963]
  ...
  [ 0.14579482  0.01390076  0.06665039  0.08001709]
  [ 0.14579482  0.01390076  0.06665039  0.06011963]
  [ 0.14579482  0.01390076  0.06665039  0.08001709]]]
[[[-0.02949784 -0.02670973  0.02227783  0.0401001 ]
  [-0.02949784 -0.09589665  0.06665039  0.06011963]
  [-0.02949784  0.00790274  0.06665039  0.06011963]
  ...
  [ 0.14579482 -0.0612842   0.06665039  0.08001709]
  [ 0.14579482 -0.0612842   0.06665039  0.06011963]
  [ 0.14579482 -0.0612842   0.06665039  0.08001709]]]
[[[-0.02949784 -0.02670973 -0.02516593  0.0401001 ]
  [-0.02949784 -0.09589665 -0.00688858  0.06011963]
  [-0.02949784  0.00790274 -0.00688858  0.06011963]
  ...
  [ 0.14579482 -0.0612842  -0.00688858  0.08001709]
  [ 0.14579482 -0.0612842  -0.00688858  0.06011963]
  [ 0.14579482 -0.0612842  -0.00688858  0.08001709]]]
[[[-0.02949784 -0.02670973 -0.02516593 -0.03145425]
  [-0.02949784 -0.09589665 -0.00688858 -0.02308007]
  [-0.02949784  0.00790274 -0.00688858 -0.02308007]
  ...
  [ 0.14579482 -0.0612842  -0.00688858 -0.01475694]
  [ 0.14579482 -0.0612842  -0.00688858 -0.02308007]
  [ 0.14579482 -0.0612842  -0.00688858 -0.01475694]]]
the Mean Square Error(MSE) of Reconstruction in Anomaly Signal : [0.12770545]
the Error of Reconstruction in Anomaly Channel C1 Signal : -1126.5865478515625
the Error of Reconstruction in Anomaly Channel C2 Signal : -1163.160400390625
the Error of Reconstruction in Anomaly Channel C3 Signal : 62.55792999267578
the Error of Reconstruction in Anomaly Channel C4 Signal : -78.83275604248047
100%|██████████████████████████████████████████████████████████| 1008/1008 [00:10<00:00, 100.08it/s]
100%|████████████████████████████████████████████████████████████| 252/252 [00:02<00:00, 101.11it/s]
/mnt/DATA1/climate/basic/SNS HVCM/ex_transformer.py:730: UserWarning: Creating legend with loc="best" can be slow with large amounts of data.
  plt.savefig('./Histogram.png', dpi=600)
/mnt/DATA1/climate/basic/SNS HVCM/ex_transformer.py:730: UserWarning: Creating legend with loc="best" can be slow with large amounts of data.
  plt.savefig('./Histogram.png', dpi=600)
추론한 결과 : 손실밀도 히스토그램 시각화
/mnt/DATA1/climate/basic/SNS HVCM/ex_transformer.py:757: UserWarning: Creating legend with loc="best" can be slow with large amounts of data.
  plt.savefig('./Histogram+KDEplot.png',dpi=600)
추론 결과 : 손실값의 커널 밀도추정 시각화
추론 결과 : 손실값의 박스 그림 시각화
